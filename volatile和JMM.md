### CPU Cache 

随着现在科技的进步，CPU和内存的性能差距越来越大，所以在CPU内部嵌入了CPU Cache 高速缓存，CPU Cache 离 CPU核心很近，因此它的访问速度很快。

CPU Cache 通常分为三级缓存： L1 Cache、L2 Cache、L3 Cache，级别越低的离CPU核心越来越近，访问速度也越快，但是容量就会越小。

### 缓存一致性问题

现在CPU都是多核，由于L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性问题。

缓存一致性问题是怎么发生的？

假设A核心和B核心同时操作共同的变量i初始值为0，A从内存中读取i值为0，此时B也读取了i值为0，两个同时做了i++的操作，然后分别把值写回了内存，i的值本应该为2，但刷回内存的值却为1，这就是缓存一致性问题。

要想实现缓存一致性，关键是要满足两点：

- **写传播**，也就是当某个CPU核心发生写入操作是，需要把该事件广播通知给其他核心。
- **事务串行化**，这个很重要，只有保证了这个，才能保证我们的数据是真正一直的，我们的程序在各个不同的核心上的结果也是一致的。

基于总线嗅探机制的MESI协议，就满足上面的这两点，因此它是保障缓存一致性的协议。

### 总线嗅探

写传播的原则就是当某个CPU核心更新了Cache 中的数据，要把该事件广播通知到其他核心。最常见的方式就是**总线嗅探**。

以前面的i变量为例。当A号CPU核心修改了L1 Cache中的i变量，通过总线把这个时间广播通知给其他所有核心，然后每个CPU核心都会监听总线上的广播事件，并检查是否具有相同的数据在自己的L1 Cache中，如果在，那么需要把该数据更新到自己的L1 Cache中。

可见，总线嗅探方法很简单，CPU需要没事没刻监听总线上的一切活动，但是不管别的核心的Cache是否缓存相同的数据，都需要发送广播，这无疑我会加重总线的负载。

另外，总线嗅探只是保证了某个核心CPU的Cache更新数据这个时间能被其他CPU核心知道，但是并不保证事务串行化。

于是，有一个协议基于总线嗅探机制实现了事务串行化，也用状态机机制降低了总线带宽压力，这个协议就是MESI协议，这个协议就做到了CPU缓存一致性。

### MESI协议

MESI协议其实是4个状态单词的开头字母缩写，分别是：

- Modified， 已修改
- Exclusive，独占
- Shared，共享
- Invalidated，已失效

这四个状态来标记Cache Line四个不同的状态。

- 已修改状态是脏标记，代表该Cache Block 上的数据已被更新过，但是还没写会到主内存里。
- 已失效状态，表示这个Cache Block 里的数据已经失效了，不可以读取该状态的数据。
- 独占和共享都代表Cache Block里的数据是干净的，也就是说，这个时候Cache block里的数据和内存里的数据是一致的。独占和共享的差别在于，独占状态的时候，数据只存储在一个CPU核心的Cache里，而其他CPU核心的Cache里没有该数据。这个时候，如果要向独占的Cache写数据，就可以直接自由的写入，因为只有这个核心里有该数据，不存在不一致问题。
- 另外，在独占状态下的数据，如果有其他核心从内存读取了相同的数据到各自的Cache，那么这个时候，独占状态下的数据就会变成共享状态。共享状态代表这个相同的数据在多个CPU核心里都有，所以要修改的时候，不能直接修改，需要先向所有其他CPU核心广播一个请求，要求先把其他的核心的Cache中对应的Cache Line标记为无效状态，然后在更新当前Cache里面的数据。

可以发现当Cache Line状态是已修改或者独占时，修改更新其数据不需要发送广播给其他CPU核心，这在一定程度上减少了总线带宽压力。

### JMM内存模型

Java线程之间的通信由Java内存模型控制，JMM决定一个线程对共享变量的写入何时对龙一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享的变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。
